{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Content Safety\n",
    "\n",
    "## Setup for Azure Content Safety\n",
    "Azure Content Safety APIs are used with API key. A secured way for developers to get these keys is from Azure Key Vault. This pattern eliminates the need to store the secrets in your code.\n",
    "\n",
    "Reference - https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/contentsafety/azure-ai-contentsafety\n",
    "\n",
    "#### Prerequisites: \n",
    "- pip install azure-ai-contentsafety\n",
    "- Your AAD Credentials have 'secrets' read access to Azure Key Vault\n",
    "- The following OS environment variables are set - \n",
    "  - The OPENAI_AUTH_TYPE variable is set to KeysFromAKVWithCLIAuth or KeysFromAKVWithMI\n",
    "  - KEY_VAULT_URL is set to your Key Vault to read secrets from\n",
    "- The following secrets should be stored in the above Azure Key Vault\n",
    "  - 'content-safety-api-key' set to the Content Safety API key\n",
    "  - 'content-safety-endpoint' set to the Content Safety Endpoint\n",
    "\n",
    "## Setup for Azure Open AI (only if the OpenAI APIs are used here)\n",
    "#### Before you start these notebooks, make sure you have the OS environment variables setup. Example provided in the env.bat file for Windows in the root folder. Default variable settings for getting the OpenAI keys from your Azure Key Vault are \n",
    "- PYTHONPATH=%cd%\\AzureOpenAIHelperFunctions\n",
    "- KEY_VAULT_URL=https://\\<YOUR AZURE KEY VAULT NAME\\>.vault.azure.net/\n",
    "- OPENAI_AUTH_TYPE=KeysFromAKVWithCLIAuth\n",
    "#### The different options for OPENAI_AUTH_TYPE are - \n",
    "- KeysFromEnv => get the credentials from OS env\n",
    "- KeysFromAKVWithCLIAuth => get the credentials from Azure Key Vault with CLI Auth\n",
    "- KeysFromAKVWithMI => get the credentials from Azure Key Vault with Managed Identity\n",
    "- KeysFromManagedId => authenticate with Managed Identity and get access to Azure Open AI\n",
    "#### If using the Azure Key Vault to get the Azure Open AI  settings, set these secrets in the vault to the vaules you get from your Azure Open AI instance.\n",
    "  - 'openai-api-key' set to the Azure Open AI API key\n",
    "  - 'openai-api-version' set to the Azure Open AI API version\n",
    "  - 'openai-endpoint' set to the Azure Open AI endpoint\n",
    "  \n",
    "#### Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Azure Content Safety Credentials from Azure Key Vault with Azure CLI Auth\n"
     ]
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.contentsafety import ContentSafetyClient\n",
    "\n",
    "from azure_content_safety_setup import set_content_safety_config\n",
    "\n",
    "key, endpoint = set_content_safety_config()\n",
    "credential = AzureKeyCredential(key)\n",
    "client = ContentSafetyClient(endpoint, credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze text without blocklists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "\n",
    "request = AnalyzeTextOptions(text=\"I will kil'ya all, you f**king mo**ns.\", \n",
    "                             categories=[TextCategory.HATE, \n",
    "                                         TextCategory.SELF_HARM, \n",
    "                                         TextCategory.VIOLENCE,\n",
    "                                         TextCategory.SEXUAL]\n",
    "                            )\n",
    "try:\n",
    "    response = client.analyze_text(request)\n",
    "except HttpResponseError as e:\n",
    "    print(\"Analyze text failed.\")\n",
    "    if e.error:\n",
    "        print(f\"Error code: {e.error.code}\")\n",
    "        print(f\"Error message: {e.error.message}\")\n",
    "        raise\n",
    "    print(e)\n",
    "    raise\n",
    "\n",
    "text = 'Content Safety Results:'\n",
    "# Check the severity (0 to 6)\n",
    "if response.hate_result:\n",
    "    text = text + \"\\n\\tHate severity: {}\".format(response.hate_result.severity)\n",
    "if response.self_harm_result:\n",
    "    text = text + \"\\n\\tSelfHarm severity: {}\".format(response.self_harm_result.severity)\n",
    "if response.violence_result:\n",
    "    text = text + \"\\n\\tViolence severity: {}\".format(response.violence_result.severity)\n",
    "if response.sexual_result:\n",
    "    text = text + \"\\n\\tSexual severity: {}\".format(response.sexual_result.severity)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read lines from a file and check for content safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[safe_content.txt]:[0]:You are awesome.\n",
      "\n",
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n",
      "[safe_content.txt]:[1]:The world is great.\n",
      "\n",
      "Content Safety Results:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 0\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.contentsafety.models import AnalyzeTextOptions, TextCategory\n",
    "import os\n",
    "\n",
    "from azure_content_safety_setup import get_content_safety\n",
    "\n",
    "text_file = 'safe_content.txt'\n",
    "text_path = os.path.join(os.getcwd(),'./data/', text_file)\n",
    "\n",
    "# Read file line by line and check for content safety\n",
    "i = 0\n",
    "with open(text_path) as f:\n",
    "    for line in f:\n",
    "        print(\"[%s]:[%s]:%s\" %(text_file, i, line))\n",
    "        # calling my function to do the job\n",
    "        result = get_content_safety(client=client, text_input=line)\n",
    "        print(result)\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a block list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blocklist created or updated: \n",
      "Created Block list name: TR_Custom_Blocked_Text_List\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import add_or_update_block_list\n",
    "\n",
    "MY_BLOCK_LIST = 'TR_Custom_Blocked_Text_List'\n",
    "MY_BLOCK_LIST_DESCRIPTION = 'TRs fun list of blocked text strings for testing and demo of the Azure Content Safety APIs'\n",
    "added_block_list = add_or_update_block_list(client = client, \n",
    "                                            block_list_name = MY_BLOCK_LIST, \n",
    "                                            block_list_description = MY_BLOCK_LIST_DESCRIPTION)\n",
    "print(\"Created Block list name: %s\" %(added_block_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add blocked text strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Add block items failed: \n",
      "Error code: InvalidRequestBody\n",
      "Error message: Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: a60c60b9-97bc-48be-9ca0-811bf5cad803, Timestamp: 2023-06-14T19:33:09Z.\n",
      "(InvalidRequestBody) Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: a60c60b9-97bc-48be-9ca0-811bf5cad803, Timestamp: 2023-06-14T19:33:09Z.\n",
      "Code: InvalidRequestBody\n",
      "Message: Some items already exist in list TR_Custom_Blocked_Text_List. items: [m0**ns,kil'ya,f**king]. | Request Id: a60c60b9-97bc-48be-9ca0-811bf5cad803, Timestamp: 2023-06-14T19:33:09Z.\n",
      "Blocked Text items: FAILED\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import add_blocked_items\n",
    "\n",
    "my_blocked_text_array = [\"kil'ya\", \"f**king\", \"m0**ns\"]\n",
    "added_text_list = add_blocked_items(\n",
    "                        client = client, \n",
    "                        block_list_name = MY_BLOCK_LIST, \n",
    "                        block_text_array = my_blocked_text_array\n",
    "                    )\n",
    "print(\"Blocked Text items: %s\" %(added_text_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze text with block list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Safety Results (blank if none found):\n",
      "  Blocklist match results: \n",
      "\tBlock item hit in text, Offset=7, Length=6\n",
      "\tBlocklistName: TR_Custom_Blocked_Text_List, BlockItemId: 1f58ef20-0968-4de6-9231-37d5cedf532e\n",
      "\tBlockItemText: kil'ya\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import get_content_safety_custom\n",
    "\n",
    "result = get_content_safety_custom(client = client, block_list_names = [MY_BLOCK_LIST], text_input = \"I will kil'ya\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Content Safety Results in file C:\\Users\\tibarar\\OneDrive - Microsoft\\Desktop\\MyProjects\\open-ai\\ResponsibleAI\\./data/image.jpg:\n",
      "\tHate severity: 0\n",
      "\tSelfHarm severity: 0\n",
      "\tViolence severity: 2\n",
      "\tSexual severity: 0\n"
     ]
    }
   ],
   "source": [
    "from azure_content_safety_setup import get_image_safety\n",
    "import os\n",
    "\n",
    "image_file = 'image.jpg'\n",
    "image_path = os.path.join(os.getcwd(),'./data/', image_file)\n",
    "\n",
    "result = get_image_safety(client = client, image_filepath = image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
